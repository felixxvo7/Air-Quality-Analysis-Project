Y <- as.matrix(targets)
set.seed(123)  # For reproducibility
train_index <- sample(1:nrow(X), size = 0.8 * nrow(X))  # 80% train, 20% test
X_train <- X[train_index, ]
Y_train <- Y[train_index, ]
X_test <- X[-train_index, ]
Y_test <- Y[-train_index, ]
library(keras3)
# library(tidyverse)
model <- keras_model_sequential(input_shape = ncol(X)) %>%
layer_dense(units = 16, activation = "relu", name = "layer1") %>%
layer_dense(units = 32, activation = "relu", name = "layer2") %>%
layer_dense(units = ncol(Y), name = "layer3")
model <- keras_model_sequential(input_shape = 4) |>
layer_dense(units = 2, activation = "relu")
knitr::opts_chunk$set(echo = TRUE)
library(reticulate)
use_python("C:/Users/DucDo/anaconda3/python.exe", required = TRUE)
library(reticulate)
# Create a new Conda environment
conda_create("r-keras", packages = "python=3.9")
use_condaenv("r-keras")
# Install compatible TensorFlow and Keras
library(keras)
install.packages("keras3")
install.packages("keras3")
install.packages("keras3")
library(keras3)
model <- keras_model_sequential(input_shape = 4) |>
layer_dense(units = 2, activation = "relu")
summary(model)
model %>% compile(
loss = 'mse',
optimizer = optimizer_rmsprop(),
metrics = c('accuracy')
)
history <- model %>% fit(
x_train, y_train,
epochs = 2, batch_size = 1,
validation_split = 0.2
)
## ----setup, include=FALSE-------------------------------------------------
tensorflow::as_tensor(1)
## -------------------------------------------------------------------------
library(tensorflow)
library(keras)
mnist <- dataset_mnist()
train_images <- mnist$train$x
train_labels <- mnist$train$y
test_images <- mnist$test$x
test_labels <- mnist$test$y
## -------------------------------------------------------------------------
str(train_images)
str(train_labels)
## -------------------------------------------------------------------------
str(test_images)
str(test_labels)
model <- keras_model_sequential(list(
layer_dense(units = 512, activation = "relu"),
layer_dense(units = 10, activation = "softmax")
))
compile(model,
optimizer = "rmsprop",
loss = "sparse_categorical_crossentropy",
metrics = "accuracy")
train_images <- array_reshape(train_images, c(60000, 28 * 28))
train_images <- train_images / 255
test_images <- array_reshape(test_images, c(10000, 28 * 28))
test_images <- test_images / 255
fit(model, train_images, train_labels, epochs = 5, batch_size = 128)
install.packages(c("keras", "tensorflow"))
install.packages("devtools")
library("devtools")
devtools::install_github("rstudio/keras", dependencies = TRUE)
library(keras)
library(tensorflow)
install_keras()
devtools::install_github("rstudio/keras3", dependencies = TRUE)
tensorflow::tf_config()
tensorflow::tf_config()
install_tensorflow()
reticulate::py_config()
keras --version
tensorflow::tf_version()
library(keras3)
install_keras()
library(keras3)
keras_config()
install.packages("keras3")
keras3::install_keras(backend = "tensorflow")
library(keras3)
# Load the MNIST dataset
mnist <- dataset_mnist()
library(keras3)
# Load the MNIST dataset
mnist <- dataset_mnist()
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
library(keras3)
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
library(reticulate)
py_config()
py_config()
Sys.setenv("RETICULATE_PYTHON" = "managed")
library(keras3)
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
unlink("~/.virtualenvs/r-keras", recursive = TRUE)
library(keras3)
keras_install()
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
library(keras3)
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
remotes::install_github("rstudio/keras3")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
model <- keras_model_sequential(input_shape = 4) %>%
layer_dense(units = 2, activation = "relu")
remove.packages(c("keras3", "tensorflow", "reticulate"))
reticulate::py_config()
reticulate:::rm_all_reticulate_state(TRUE)
reticulate::py_config()
Sys.setenv(RETICULATE_PYTHON = "C:\Users\DucDo\Anaconda3\python.exe")
Sys.setenv(RETICULATE_PYTHON = "C:/Users/DucDo/Anaconda3/python.exe")
reticulate::py_config()
reticulate::virtualenv_remove("r-keras")
remotes::install_github(c("rstudio/reticulate", "rstudio/keras3", "rstudio/tensorflow"), force = TRUE)
Sys.setenv("RETICULATE_PYTHON"="managed")
library(keras3)
op_convert_to_tensor("Hello World!")
library(keras3)
# Load the MNIST dataset
mnist <- dataset_mnist()
train_images <- mnist$train$x
train_labels <- mnist$train$y
test_images <- mnist$test$x
test_labels <- mnist$test$y
# Inspect the data
str(train_images)
str(train_labels)
str(test_images)
str(test_labels)
# Build the model
model <- keras_model_sequential() %>%
layer_dense(units = 256, activation = 'relu', input_shape = c(784)) %>%
layer_dropout(rate = 0.4) %>%
layer_dense(units = 128, activation = 'relu') %>%
layer_dropout(rate = 0.3) %>%
layer_dense(units = 10, activation = 'softmax')
# Compile the model
compile(model,
optimizer = "rmsprop",
loss = "sparse_categorical_crossentropy",
metrics = "accuracy")
# Reshape and normalize the data
train_images <- array(train_images, dim = c(60000, 28 * 28))
train_images <- train_images / 255
test_images <- array(test_images, dim = c(10000, 28 * 28))
test_images <- test_images / 255
# Train the model
fit(model, train_images, train_labels, epochs = 5, batch_size = 128)
reticulate::conda_list()
reticulate::py_config()
reticulate::conda_list()
Sys.setenv("RETICULATE_PYTHON"="C:\\Users\\DucDo\\anaconda3\\python.exe")
library(keras3)
op_convert_to_tensor("Hello World!")
Sys.setenv("RETICULATE_PYTHON"="managed")
library(keras3)
op_convert_to_tensor("Hello World!")
setwd("C:/Users/DucDo/OneDrive-UniversityofManitoba/Documents/University_documents/UofM/WInter2025/DATA2010/Air-Quality-Analysis-Project")
df = read.csv("final_cleaned_data.csv")
head(df)
typeof(df)
# 3. Better alternative using ggplot2
library(ggplot2)
library(reshape2) # For melt() function
correlation_heatmap = function(cor_matrix) {
# Convert correlation matrix to long format
melted_cor <- melt(cor_matrix)
# Create heatmap
ggplot(melted_cor, aes(Var1, Var2, fill = value)) +
geom_tile() +
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1)) +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
coord_fixed()
}
library(tidyverse)
# Define predictors (exclude Date, Time, and targets)
predictors <- df %>% select(-c(Date, Time, CO.GT., C6H6.GT., NOx.GT., NO2.GT.))
# Define multiple target variables (CO, NOx, Benzene)
targets <- df %>% select(CO.GT., C6H6.GT., NOx.GT., NO2.GT.)
# Normalize data (optional but recommended)
normalize <- function(x) {
(x - min(x)) / (max(x) - min(x))
}
predictors <- as.data.frame(lapply(predictors, normalize))
head(predictors)
X <- as.matrix(predictors)
# Y <- as.matrix(targets)
correlation_heatmap(cor(X))
# 1. Calculate correlation matrix (excluding columns 1 & 2)
cor_matrix <- cor(as.matrix(df[-c(1, 2)]))
correlation_heatmap(cor_matrix = cor_matrix)
predictors <- predictors %>% selelect(-c("T", "RH", "AH"))
predictors <- predictors %>% select(-c("T", "RH", "AH"))
head(predictors)
install.packages("FNN")
library(FNN)
# Split into training and testing sets
set.seed(123)
trainIndex <- sample(1:nrow(df), size = 0.8 * nrow(df))
train_x <- predictors[trainIndex, ]
train_y <- targets[trainIndex, ]
test_x <- predictors[-trainIndex, ]
test_y <- targets[-trainIndex, ]
# Train kNN regression model
knn_result <- knn.reg(train = train_x,
test = test_x,
y = train_y,
k = 5)  # k = 5 nearest neighbors
predictions <- knn_result$pred
mse <- colMeans((predictions - as.matrix(test_y))^2)  # Compute MSE for each target
mse
View(df)
############################ use caret library
library(caret)
install.packages("caret")
library(caret)
# Concatenate train_x and train_y to create the full training dataset
train <- cbind(train_x, train_y)
# Now, train_full can be passed to the train() function
knn_fit <- train(CO.GT. + C6H6.GT. + NOx.GT. + NO2.GT. ~ .,
data = train,
method = "knn",
tuneGrid = expand.grid(k = 5),  # Specify number of neighbors
trControl = trainControl(method = "cv", number = 10))  # Cross-validation
# Predictions
predictions_caret <- predict(knn_fit, newdata = test_x)
mse_caret <- mean((predictions_caret - test_y)^2)
mse_caret
type(predictions)
typeof(predictions)
?knn.reg
knn_result <- function(target) {
# Train kNN regression model
knn_fit <- knn.reg(train = train_x,
test = test_x,
y = train_y[[target]],
k = 5)  # k = 5 nearest neighbors
# Predictions
predictions <- knn_fit$pred
# Evaluate model performance for multiple targets
mse <- mean((predictions - test_y[[target]])^2)  # Compute MSE for each target
mse
}
# Example usage for one target variable:
mse_CO <- knn_result("CO.GT.")
mse_C6H6 <- knn_result("C6H6.GT.")
mse_NOx <- knn_result("NOx.GT.")
mse_NO2 <- knn_result("NO2.GT.")
# Display MSE for each target
mse_CO
mse_C6H6
mse_NOx
mse_NO2
knn_result("NO2.GT.")
knn_result <- function(target) {
# Train kNN regression model
knn_fit <- knn.reg(train = train_x,
test = test_x,
y = train_y[[target]],
k = 5)  # k = 5 nearest neighbors
# Predictions
predictions <- knn_fit$pred
# Evaluate model performance for multiple targets
mse <- mean((predictions - test_y[[target]])^2)  # Compute MSE for each target
# return (mse)
# Normalize MSE by the mean of the actual values
target_mean <- mean(test_y[[target]])
mse_normalized <- mse / target_mean
return(mse_normalized)  # Return the normalized MSE for this target
}
knn_result("NO2.GT.")
# Example usage for one target variable:
mse_CO <- knn_result("CO.GT.") # 0.3430058
mse_C6H6 <- knn_result("C6H6.GT.") # 15.61902
mse_NOx <- knn_result("NOx.GT.") # 5837.382
mse_NO2 <- knn_result("NO2.GT.") # 453.9531
### Still pretty bad
# Display MSE for each target
mse_CO
mse_C6H6
mse_NOx
mse_NO2
library(caret)
# Concatenate train_x and train_y to create the full training dataset
train <- cbind(train_x, train_y)
# Now, train_full can be passed to the train() function
knn_fit <- train(CO.GT. + C6H6.GT. + NOx.GT. + NO2.GT. ~ .,
data = train,
method = "knn",
tuneGrid = expand.grid(k = 5),  # Specify number of neighbors
trControl = trainControl(method = "cv", number = 10))  # Cross-validation
# Predictions
predictions_caret <- predict(knn_fit, newdata = test_x)
# Evaluate performance
mse_caret <- mean((predictions_caret - test_y)^2)
mse_caret
library(caret)
# List of target variables
target_names <- c("CO.GT.", "C6H6.GT.", "NOx.GT.", "NO2.GT.")
# Initialize an empty list to store the predictions
predictions_caret_list <- list()
# Loop through each target and train a model
for (target in target_names) {
# Train kNN model for each target variable
knn_fit <- train(
as.formula(paste(target, "~ .")),
data = train,
method = "knn",
tuneGrid = expand.grid(k = 5),  # Specify number of neighbors
trControl = trainControl(method = "cv", number = 10)  # Cross-validation
)
# Make predictions
predictions_caret_list[[target]] <- predict(knn_fit, newdata = test_x)
}
train = cbind(train_x, train_y)
# List of target variables
target_names <- c("CO.GT.", "C6H6.GT.", "NOx.GT.", "NO2.GT.")
# Initialize an empty list to store the predictions
predictions_caret_list <- list()
# Loop through each target and train a model
for (target in target_names) {
# Train kNN model for each target variable
knn_fit <- train(
as.formula(paste(target, "~ .")),
data = train,
method = "knn",
tuneGrid = expand.grid(k = 5),  # Specify number of neighbors
trControl = trainControl(method = "cv", number = 10)  # Cross-validation
)
# Make predictions
predictions_caret_list[[target]] <- predict(knn_fit, newdata = test_x)
}
# Train KNN model using caret
knn_fit <- train(CO.GT. ~ .,
data = train,
method = "knn",
tuneGrid = expand.grid(k = 5),  # Specify number of neighbors
trControl = trainControl(method = "cv", number = 10))  # Cross-validation
# Predictions
predictions_caret <- predict(knn_fit, newdata = test_x)
# Train KNN model using caret
knn_fit <- train(CO.GT. ~ PT08.S1.CO. + PT08.S2.NMHC. + PT08.S3.NOx. + PT08.S4.NO2. + PT08.S5.O3.,
data = train,
method = "knn",
tuneGrid = expand.grid(k = 5),  # Specify number of neighbors
trControl = trainControl(method = "cv", number = 10))  # Cross-validation
# Predictions
predictions_caret <- predict(knn_fit, newdata = test_x)
# Evaluate performance
mse_caret <- mean((predictions_caret - test_y$CO.GT.)^2)
mse_caret
target_names <- c("CO.GT.", "C6H6.GT.", "NOx.GT.", "NO2.GT.")
# Initialize an empty list to store the predictions
predictions_caret_list <- list()
# Loop through each target and train a model
for (target in target_names) {
# Train kNN model for each target variable
knn_fit <- train(
as.formula(paste(target, "~ PT08.S1.CO. + PT08.S2.NMHC. + PT08.S3.NOx. + PT08.S4.NO2. + PT08.S5.O3.")),
data = train,
method = "knn",
tuneGrid = expand.grid(k = 5),  # Specify number of neighbors
trControl = trainControl(method = "cv", number = 10)  # Cross-validation
)
# Make predictions
predictions_caret_list[[target]] <- predict(knn_fit, newdata = test_x)
}
# Check the predictions for each target
predictions_caret_list
# Initialize an empty list to store the normalized MSE for each target
normalized_mse_list <- list()
# Loop through each target and calculate normalized MSE
for (target in targets) {
# Get the actual values for the target from the test dataset
actual_values <- test_y[[target]]
# Get the predicted values for the target from the predictions_caret_list
predicted_values <- predictions_caret_list[[target]]
# Calculate the Mean Squared Error (MSE)
mse <- mean((predicted_values - actual_values)^2)
# Calculate the mean of the actual values (for normalization)
mean_actual <- mean(actual_values)
# Normalize the MSE
normalized_mse <- mse / mean_actual
# Store the normalized MSE in the list
normalized_mse_list[[target]] <- normalized_mse
}
knn_fit <- train(CO.GT. ~ PT08.S1.CO. + PT08.S2.NMHC. + PT08.S3.NOx. + PT08.S4.NO2. + PT08.S5.O3.,
data = train,
method = "knn",
tuneGrid = expand.grid(k = 5),  # Specify number of neighbors
trControl = trainControl(method = "cv", number = 10))  # Cross-validation
# Predictions
predictions_caret <- predict(knn_fit, newdata = test_x)
# Evaluate performance
mse_caret <- mean((predictions_caret - test_y$CO.GT.)^2)
mse_caret
knn_fit <- train(C6H6.GT. ~ PT08.S1.CO. + PT08.S2.NMHC. + PT08.S3.NOx. + PT08.S4.NO2. + PT08.S5.O3.,
data = train,
method = "knn",
tuneGrid = expand.grid(k = 5),  # Specify number of neighbors
trControl = trainControl(method = "cv", number = 10))  # Cross-validation
# Predictions
predictions_caret <- predict(knn_fit, newdata = test_x)
# Evaluate performance
mse_caret <- mean((predictions_caret - test_y$CO.GT.)^2)
mse_caret
knn_fit <- train(NOx.GT. ~ PT08.S1.CO. + PT08.S2.NMHC. + PT08.S3.NOx. + PT08.S4.NO2. + PT08.S5.O3.,
data = train,
method = "knn",
tuneGrid = expand.grid(k = 5),  # Specify number of neighbors
trControl = trainControl(method = "cv", number = 10))  # Cross-validation
# Predictions
predictions_caret <- predict(knn_fit, newdata = test_x)
# Evaluate performance
mse_caret <- mean((predictions_caret - test_y$CO.GT.)^2)
mse_caret
knn_fit <- train(NO2.GT. ~ PT08.S1.CO. + PT08.S2.NMHC. + PT08.S3.NOx. + PT08.S4.NO2. + PT08.S5.O3.,
data = train,
method = "knn",
tuneGrid = expand.grid(k = 5),  # Specify number of neighbors
trControl = trainControl(method = "cv", number = 10))  # Cross-validation
# Predictions
predictions_caret <- predict(knn_fit, newdata = test_x)
# Evaluate performance
mse_caret <- mean((predictions_caret - test_y$CO.GT.)^2)
mse_caret
